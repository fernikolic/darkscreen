name: Weekly Auth Crawl & Deploy

on:
  schedule:
    # Every Monday at 9 AM UTC (3 hours after public crawl)
    - cron: "0 9 * * 1"
  workflow_dispatch:

concurrency:
  group: weekly-crawl-auth
  cancel-in-progress: false

jobs:
  auth-crawl-and-deploy:
    runs-on: ubuntu-latest
    timeout-minutes: 240

    steps:
      # ─── Setup ─────────────────────────────────────────────────
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Node 20
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: npm

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright Chromium
        run: npx playwright install chromium --with-deps

      # ─── Download current screenshots from R2 ──────────────────
      # Needed so archive + diff can compare old vs new
      - name: Download screenshots from R2
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        run: bash scripts/download-r2-screenshots.sh

      # ─── Download encrypted profiles from R2 ──────────────────
      - name: Download encrypted profiles from R2
        env:
          DARKSCREEN_CRED_KEY: ${{ secrets.DARKSCREEN_CRED_KEY }}
        run: bash scripts/download-profiles.sh

      # ─── Archive current state (for diffing later) ─────────────
      - name: Archive current screenshots
        run: node scripts/archive-screens.mjs --all

      # ─── Recrawl login apps ────────────────────────────────────
      - name: Recrawl stale login apps (7+ days old)
        run: node scripts/recrawl-stale.mjs --days 7 --auth-only

      # ─── Upload fresh profiles back to R2 ──────────────────────
      # Session cookies may have been refreshed during crawl
      - name: Upload fresh profiles to R2
        env:
          DARKSCREEN_CRED_KEY: ${{ secrets.DARKSCREEN_CRED_KEY }}
        run: bash scripts/upload-profiles.sh

      # ─── Diff & generate change records ────────────────────────
      - name: Diff screenshots against archive
        run: node scripts/diff-screens.mjs --all

      - name: Generate auto-detected changes
        run: node scripts/generate-changes.mjs --all

      # ─── Upload new/changed screenshots to R2 ─────────────────
      - name: Upload screenshots to R2
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          PARALLEL: "25"
        run: bash scripts/upload-screenshots.sh --all

      # ─── Commit data changes ───────────────────────────────────
      - name: Commit data changes
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add src/data/apps.ts src/data/auto-changes.ts
          if git diff --cached --quiet; then
            echo "No data changes to commit."
          else
            git commit -m "chore: weekly auth crawl — update login app screenshots and change data"
            git push
          fi

      # ─── Build & Deploy ────────────────────────────────────────
      - name: Build
        run: npm run build

      - name: Deploy to Cloudflare Pages
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        run: npx wrangler pages deploy out --project-name=darkscreen
